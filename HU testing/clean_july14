
## upload the data from the excel file 20200707_Protein amount
library(readxl)
cath_all         <- read_excel("20200707_Protein amount.xlsx", sheet = "on catheter")
cath_after_5mins <- read_excel("20200707_Protein amount.xlsx", sheet = "on catheter_after 5min")
HU               <- read_excel("20200707_Protein amount.xlsx", sheet = "human urine solution")


# merge the columns by UniProt ID for the data 'on catheter starting after 5 mins' and 'HU' 
merge_cath_5min <- merge(cath_after_5mins, HU, by= 'PG.UniProtIds')
dim(merge_cath_5min)  # get a total of 535 cases


##########################################################################
## view visualization graphs box plots and scatter plots
boxplot(merge_cath_5min$`5min`)
plot(merge_cath_5min$`5min`)
boxplot(merge_cath_5min$`15min`)


# note here we are using the pairs plot to get a matrix scatter plot of our selected variables 
pairs(merge_cath_5min[,c(13,4:10)])       # regular graph of the data
pairs(log(merge_cath_5min[,c(13,4:10)]))  # log of the data

#have some outliers
#############################################################################
# remove the outliers we will keep all values within 3 standard deviations from the mean


data = merge_cath_5min[,4:10]
findOutlier <- function(data, cutoff = 3) {
  ## Calculate the sd
  sds <- apply(data, 2, sd, na.rm = TRUE)
  ## Identify the cells with value greater than cutoff * sd (column wise)
  result <- mapply(function(d, s) {
    which(d > cutoff * s)
  }, data, sds)
  result
}
## get a list of outliers for the samples based on data frame index
outliers <- findOutlier(merge_cath_5min)
outliers

## remove the outliers
removeOutlier <- function(data, outliers) {
  result <- mapply(function(d, o) {
    res <- d
    res[o] <- NA
    return(res)
  }, data, outliers)
  return(as.data.frame(result))
}

# each outlier is removed and replaced with NA
dataFilt <- removeOutlier(merge_cath_5min, outliers)
View(dataFilt)

# omit every row that has NA value
# from 535 --> 506 cases ==> (removed 29 total outliers)
data.Filt<-na.omit(dataFilt)
colnames(data.Filt)
col.num <- c("5min","15min",  "30min" ,      "3h"  , "6h" ,                     
              "18h" ,  "24h"  ,"HU Amount (ug)"    )
data.Filt[col.num]<-sapply(data.Filt[col.num],as.numeric)  # change these columns back to numeric 
sapply(data.Filt,class)

#observe the visualization boxplot and scatter plot for 5 mins
# still have what could be considered as an outlier, but still improved from before 
boxplot(data.Filt$`5min`)  
plot(data.Filt$`5min`)

#rename data frame
merge_cath_5min_noOutliers = data.Filt
write.csv(merge_cath_5min_noOutliers, "merge_cath_5min_noOutliers.csv")

# pivot the time from 5min to 24 hours again
library(tidyr)
#pivot the time sample into one column
merge_cath_5min_noOutliers_pivot   <- gather(merge_cath_5min_noOutliers, Time, Value, "5min":"24h", factor_key = TRUE)

write.csv(merge_cath_5min_noOutliers_pivot, "merge_cath_5min_noOutliers_pivot.csv")


#####
# merge all of the sample with HU by UniProd IDS
mergeing_all<- merge(cath_all,HU,by='PG.UniProtIds')
write.csv(mergeing_all,"mergeing_all.csv")


# pivot the time from 5min to 24 hours
#library(tidyr)
cath1   <- gather(merge_cath_5min, Time, Value, "5min":"24h", factor_key = TRUE)
# merge the samples after 5mins with HU by UniProt ID
merge_after5mins <-merge(cath1, HU, by='PG.UniProtIds')
write.csv(merge_after5mins,"merge_after5mins_with_outliers.csv")







#------tests-----------
# possible different types of tests to explore
#correlation test refular data set
cor(data.Filt[,c(13,4:10)])
pairs(data.Filt[,c(13,4:10)])

# cor using the spearman method and log of the scatter plots
cor(data.Filt[,c(13,4:10)],method='spearman')
pairs(log(data.Filt[,c(13,4:10)]))

par(mfrow=c(2, 4))
hist(data.Filt$`5min`)
hist(data.Filt$`15min`)
hist(data.Filt$`30min`)
hist(data.Filt$`3h`)
hist(data.Filt$`6h`)
hist(data.Filt$`18h`)
hist(data.Filt$`24h`)



hist(data.Filt$`HU Amount (ug)`)






library(readxl)

# (X20200707_Protein_amount)
cath_all         <- read_excel("20200707_Protein amount.xlsx", sheet = "on catheter")
HU_all           <- read_excel("20200707_Protein amount.xlsx", sheet = "human urine solution")
# merge original data file
data_all <- merge(cath_all,HU_all, by = 'PG.UniProtIds')  # share a total of 885 cases


# 20210713 Protein GRAVY value
cath_gravy       <- read_excel("20210713 Protein GRAVY value.xlsx", sheet = "on catheter")
HU_gravy         <- read_excel("20210713 Protein GRAVY value.xlsx", sheet = "in HU")
# merge the gravy excel files
data_gravy <- merge(cath_gravy,HU_gravy, by = 'PG.UniProtIds')


## merging all the files into one 
data_list <- list(cath_all, HU_all, cath_gravy, HU_gravy)      # Combine data frames to list
my_merge <- function(df1, df2){                                # Create own merging function
  merge(df1, df2, by = "PG.UniProtIds")
}
combine_df<-Reduce(my_merge, data_list)                            # Apply Reduce to own function
dim(combine_df)  # have total of 885 cases sharing the same column ==> 'PG.UniProtIds'



library(dplyr)
# remove duplicate columns
combine_df <- combine_df[, !duplicated(colnames(combine_df))]
colnames(combine_df)

# remove extra columns 
combine_df<-select(combine_df, -c("PG.Genes.y" , 
                      "PG.ProteinDescriptions.y", 
                      "Sequence.y"  , 
                      "GRAVY.y" , 
                      "|GRAVY|.y"  ,
                      "Sequence length.y", 
                      "pI.y" , 
                      "Lysine.y" ,
                      "avg_mass.y" ,
                      "PG.Genes.y"   ,
                      "PG.ProteinDescriptions.y"))
# rename the columns
combine_df <- rename(combine_df, c( "PG.Genes" = "PG.Genes.x" ,           
                                    "PG.ProteinDescriptions" = "PG.ProteinDescriptions.x",
                                    "Sequence" = "Sequence.x"   ,          
                                    "GRAVY" = "GRAVY.x"     ,            
                                    "|GRAVY|" = "|GRAVY|.x"   ,            
                                    "Sequence length"  = "Sequence length.x"  ,      
                                    "pI" ="pI.x"                    ,
                                    "Lysine"   = "Lysine.x"       ,          
                                    "avg_mass"  = "avg_mass.x"  ))
colnames(combine_df)
dim(combine_df) # 885 cases and 18 columns

# have some missing values need to remove
combine_df2 <- na.omit(combine_df);dim(combine_df2) ## 885 --> 879 (have 10 cases with NA values)


cor(combine_df2[,c(11,4:10,13:18)])

pairs(combine_df2[,c(11,4:10,13:18)])
pairs(combine_df2[,c(11,13:18)])
pairs(combine_df2[,c(11,4:7,13:18)])

pairs(log(combine_df2[,c(11,4:10,13:18)]))


par(mfrow=c(2,4))
plot(combine_df2$`5min (ug)`, combine_df2$GRAVY)
plot(combine_df2$`15min (ug)`, combine_df2$GRAVY)
plot(combine_df2$`30min (ug)`, combine_df2$GRAVY)
plot(combine_df2$`3h (ug)`, combine_df2$GRAVY)
plot(combine_df2$`6h (ug)`, combine_df2$GRAVY)

plot(combine_df2$`18h (ug)`, combine_df2$GRAVY)
plot(combine_df2$`24h (ug)`, combine_df2$GRAVY)
plot(combine_df2$`HU Amount (ug)`, combine_df2$GRAVY)




par(mfrow=c(2,4))
plot(combine_df2$`5min (ug)`, combine_df2$pI)
plot(combine_df2$`15min (ug)`, combine_df2$pI)
plot(combine_df2$`30min (ug)`, combine_df2$pI)
plot(combine_df2$`3h (ug)`, combine_df2$pI)
plot(combine_df2$`6h (ug)`, combine_df2$pI)

plot(combine_df2$`18h (ug)`, combine_df2$pI)
plot(combine_df2$`24h (ug)`, combine_df2$pI)
plot(combine_df2$`HU Amount (ug)`, combine_df2$pI)

plot(combine_df2$GRAVY)




hist(combine_df2$GRAVY)

plot(combine_df2$`Sequence length`)

plot(combine_df2$pI)


packages <- c("openxlsx", "readxl", "magrittr", "purrr", "ggplot2")

if (!require(install.load)) {
  install.packages("install.load")
}

install.load::install_load(packages)
write.xlsx(combine_df2,"combine_df2.xlsx")







############
#     remove some outliers based on 3sd from the mean
data = combine_df2[,4:11]
data2 = data.Filt[,13:18]
findOutlier <- function(data2, cutoff = 3) {
  ## Calculate the sd
  sds <- apply(data2, 2, sd, na.rm = TRUE)
  ## Identify the cells with value greater than cutoff * sd (column wise)
  result <- mapply(function(d, s) {
    which(d > cutoff * s)
  }, data2, sds)
  result
}
## get a list of outliers for the samples based on data frame index
outliers <- findOutlier(data2)
outliers

## remove the outliers
removeOutlier <- function(data, outliers) {
  result <- mapply(function(d, o) {
    res <- d
    res[o] <- NA
    return(res)
  }, data, outliers)
  return(as.data.frame(result))
}

# each outlier is removed and replaced with NA
dataFilt <- removeOutlier(data2, outliers)
View(dataFilt)


combine_df2[,c(4:11)] <- dataFilt[,c(1:8)]
write.csv(combine_df2, "dataframe.withoutliers.csv")
combine_df3<- combine_df2
# omit every row that has NA value
# from 879 --> 855 cases ==> (removed 24 total outliers)
data.Filt<-na.omit(combine_df3)
write.csv(data.Filt, 'cleaned up.csv')

df.pivot<-  gather(data.Filt, Time, Value, "5min (ug)":"24h (ug)", factor_key = TRUE)
write.csv( df.pivot, 'cleandatapilot.csv')

plot(data.Filt$`5min (ug)`, data.Filt$pI)

hist(data.Filt$GRAVY)
hist(data.Filt$`|GRAVY|`)
hist(data.Filt$pI)
hist(data.Filt$Lysine)









